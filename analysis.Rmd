---
title: "Untitled"
author: "James Bain"
date: "3/14/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(readr)
library(purrr)
library(sf)
library(haterzmapper)
source("R/cleaning_functions.R")
```

```{r}
# the three immigration related keywords
# refugees, illegals and immigrant
ref <- clean_tweeter("~/Dropbox/tweets/paper2/rawdata/refugees_nort.csv")
ill <- clean_tweeter("~/Dropbox/tweets/paper2/rawdata/illegals_nort.csv")
immi <- clean_tweeter("~/Dropbox/tweets/paper2/rawdata/immigrants_nort.csv")

# and the baseline
gen <- clean_tweeter("~/Dropbox/tweets/paper2/rawdata/generic_nort.csv")
```

```{r}
#tweetids <- tibble(tweet_id_str = c(ref$tweet_id_str, ill$tweet_id_str, immi$tweet_id_str))

tweetids <- c(ref$tweet_id_str, ill$tweet_id_str, immi$tweet_id_str, gen$tweet_id_str)

uniq_tweetids <- unique(tweetids)

length(uniq_tweetids)

newids <- sprintf("j%020d", sample(1:length(uniq_tweetids), replace = F))

id_df <- tibble(tweet_id_str = uniq_tweetids, new_ids = newids)

ref2 <- ref %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
ill2 <- ill %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
immi2 <- immi %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
gen2 <- gen %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
```
```{r}
# the tweet_id_str of all of the keyword files
tweetids <- tibble(tweet_id_str = c(ref$tweet_id_str, ill$tweet_id_str, immi$tweet_id_str))

# overwrite the original `gen` data with the removed indexes
gen <- gen %>% anti_join(tweetids)

tweetids2 <- tibble(tweet_id_str = c(ref2$tweet_id_str, ill2$tweet_id_str, immi2$tweet_id_str))

# overwrite the original `gen` data with the removed indexes
gen2 <- gen2 %>% anti_join(tweetids2)
```
```{r}
# get count data from msas from 
# ~/Documents/research/TweetingLocale/papers/city_scaling/analyses/diversity_scaling.Rmd
msa_counts <- read_csv("~/Dropbox/census/acs_msa_counts.csv") %>% mutate(msa_geoid = as.character(msa_geoid))
research_cities <- read_csv("~/Documents/research/TweetingLocale/data/research_cities.csv") 


# get msa id for each job
msa_jobs <- research_cities %>%
  left_join(haterzmapper::topcities) %>%
  arrange(msa_geoid)

# find msa_geoids and map to job_ids
msa_jobs %>% left_join(msa_counts) %>%
  arrange(rank) %>%
  distinct(msa_geoid, .keep_all = T)

# create an sf frame of city points
cities_sf <- topcities %>% 
  dplyr::select(rank, full_name, lon, lat, msa_geoid) %>% 
  rename(city_name = full_name) %>% 
  right_join(msa_jobs %>% distinct(msa_geoid)) %>% 
  arrange(rank) %>% 
  distinct(msa_geoid, .keep_all = T) %>%
  st_as_sf(coords = c("lon", "lat")) %>%
  st_set_crs(4326)
```

```{r}
cnames <- c('tweet_id_str', 'job_id', 'created_at', 'none', 'med', 'high')

ref_ang <- clean_predtweets(
        file = "~/Dropbox/tweets/paper2/predicted/pretrained_embeddings_predictions/anger_pred_pretr_refugees_nort.csv",
        join_data = ref,
        colnames = cnames)

ill_ang <- clean_predtweets(
        file = "~/Dropbox/tweets/paper2/predicted/pretrained_embeddings_predictions/anger_pred_pretr_illegals_nort.csv",
        join_data = ill,
        colnames = cnames)

immi_ang <- clean_predtweets(
        file = "~/Dropbox/tweets/paper2/predicted/pretrained_embeddings_predictions/anger_pred_pretr_immigrants_nort.csv",
        join_data = immi,
        colnames = cnames)

ref_ang2 <- ref_ang %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
ill_ang2 <- ill_ang %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
immi_ang2 <- immi_ang %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)

# 
gen_ang <- map(list.files("~/Dropbox/tweets/paper2/predicted/pretrained_embeddings_predictions/", 
               pattern = "anger_pred_pretr_generic*", 
               full.names = T), 
    .f = function(x){
      read_csv(x, 
               col_names = cnames, 
               col_types = cols(tweet_id_str = col_character()))
      }
    ) %>% 
  reduce(.f = bind_rows) %>%
  distinct(tweet_id_str, .keep_all = T) %>%
  find_argmax() %>%
  left_join(gen) %>% 
  distinct(tweet_id_str, .keep_all = T) %>% 
  preprocess() %>% 
  transform_prediction(msa_jobs, anger)

gen_ang2 <- gen_ang %>% left_join(id_df) %>% select(-tweet_id_str) %>% rename(tweet_id_str = new_ids)
```
